{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "55c8c667",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     /Users/yaswanthganapathi/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download(\"punkt\")\n",
    "from newspaper import Article\n",
    "from bs4 import BeautifulSoup\n",
    "import nltk\n",
    "from gtts import gTTS\n",
    "import os\n",
    "from TTS.api import TTS\n",
    "import requests\n",
    "import pandas as pd\n",
    "import speech_recognition as sr\n",
    "import time\n",
    "import pyaudio\n",
    "import wave"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3bd32106",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No model was supplied, defaulted to sshleifer/distilbart-cnn-12-6 and revision a4f8f3e (https://huggingface.co/sshleifer/distilbart-cnn-12-6).\n",
      "Using a pipeline without specifying a model name and revision in production is not recommended.\n",
      "Hardware accelerator e.g. GPU is available in the environment, but no `device` argument is passed to the `Pipeline` object. Model will be on CPU.\n"
     ]
    }
   ],
   "source": [
    "from transformers import pipeline\n",
    "summarizer = pipeline(\"summarization\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73c0ed02",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Welcome to the Stock News Assistant!\n",
      " > Text splitted to sentences.\n",
      "['Welcome to the Stock News Assistant!']\n",
      " > Processing time: 7.671520948410034\n",
      " > Real-time factor: 1.6683469791743064\n",
      " > Text splitted to sentences.\n",
      "['Say exit to quit.']\n",
      " > Processing time: 10.586360216140747\n",
      " > Real-time factor: 1.6759710135403754\n",
      "Please speak the company name...\n",
      " > Text splitted to sentences.\n",
      "['Please speak the company name']\n",
      " > Processing time: 15.592488050460815\n",
      " > Real-time factor: 1.706376367389924\n",
      "You said: give me the stock news for IBM\n",
      " > Text splitted to sentences.\n",
      "['You said give me the stock news for IBM']\n",
      " > Processing time: 10.953891277313232\n",
      " > Real-time factor: 1.7090265387237968\n",
      "Processing news for IBM...\n",
      " > Text splitted to sentences.\n",
      "['Processing news for IBM...']\n",
      " > Processing time: 8.978206872940063\n",
      " > Real-time factor: 1.6772524531341366\n",
      " > Text splitted to sentences.\n",
      "['Article 2']\n",
      " > Processing time: 8.153517961502075\n",
      " > Real-time factor: 1.6639370562261286\n",
      " > Text splitted to sentences.\n",
      "['Title: Nvidia-Backed Hugging Face CEO Makes 6 Predictions For 2025: Expect Robotics Growth, Valuation Cuts For AI - NVIDIA  ( NASDAQ:NVDA )']\n",
      " > Processing time: 28.45553708076477\n",
      " > Real-time factor: 1.8221870284572719\n",
      " > Text splitted to sentences.\n",
      "['From: Benzinga']\n",
      " > Processing time: 4.461848020553589\n",
      " > Real-time factor: 1.6419183720495099\n",
      " > Text splitted to sentences.\n",
      "['Summary: Nvidia-Backed Hugging Face CEO Makes 6 Predictions For 2025: Expect Robotics Growth, Valuation Cuts For AI Many companies dealing in artificial intelligence (AI) saw their valuations skyrocket in 2024..', '.']\n",
      " > Processing time: 46.64159178733826\n",
      " > Real-time factor: 1.9193175181225899\n",
      "\n",
      "Article 2:\n",
      "Title: Nvidia-Backed Hugging Face CEO Makes 6 Predictions For 2025: Expect Robotics Growth, Valuation Cuts For AI - NVIDIA  ( NASDAQ:NVDA ) \n",
      "Source: Benzinga\n",
      "Summary: Nvidia-Backed Hugging Face CEO Makes 6 Predictions For 2025: Expect Robotics Growth, Valuation Cuts For AI Many companies dealing in artificial intelligence (AI) saw their valuations skyrocket in 2024...\n",
      "\n",
      " > Text splitted to sentences.\n",
      "['You can say another company name or say exit to quit.']\n",
      " > Processing time: 12.040587663650513\n",
      " > Real-time factor: 1.7546193162703143\n",
      "Please speak the company name...\n",
      " > Text splitted to sentences.\n",
      "['Please speak the company name']\n",
      " > Processing time: 5.820269823074341\n",
      " > Real-time factor: 1.6707059674910074\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "import speech_recognition as sr\n",
    "from TTS.api import TTS\n",
    "import pyaudio\n",
    "import wave\n",
    "import time\n",
    "\n",
    "def play_audio(file_path):\n",
    "    \"\"\"Play audio using pyaudio\"\"\"\n",
    "    try:\n",
    "        wf = wave.open(file_path, 'rb')\n",
    "        p = pyaudio.PyAudio()\n",
    "\n",
    "        # Open a stream\n",
    "        stream = p.open(format=p.get_format_from_width(wf.getsampwidth()),\n",
    "                        channels=wf.getnchannels(),\n",
    "                        rate=wf.getframerate(),\n",
    "                        output=True)\n",
    "\n",
    "        # Read data and play audio\n",
    "        data = wf.readframes(1024)\n",
    "        while data:\n",
    "            stream.write(data)\n",
    "            data = wf.readframes(1024)\n",
    "\n",
    "        # Stop stream and close\n",
    "        stream.stop_stream()\n",
    "        stream.close()\n",
    "        p.terminate()\n",
    "        wf.close()\n",
    "    except Exception as e:\n",
    "        print(f\"Error playing audio: {e}\")\n",
    "\n",
    "def speak(text, output_path=\"Voice_Output.wav\"):\n",
    "    \"\"\"Speak text using preloaded TTS model and voice cloning\"\"\"\n",
    "    if not text:\n",
    "        return\n",
    "\n",
    "    try:\n",
    "        # Generate the cloned voice output\n",
    "        TTS_MODEL.tts_to_file(text=text, file_path=output_path, speaker_wav=SPEAKER_WAV, language=\"en\")\n",
    "\n",
    "        # Play the audio file\n",
    "        play_audio(output_path)\n",
    "    except Exception as e:\n",
    "        print(f\"Error in speech synthesis: {e}\")\n",
    "\n",
    "def get_voice_input():\n",
    "    \"\"\"Get voice input from user and convert to text\"\"\"\n",
    "    recognizer = sr.Recognizer()\n",
    "    with sr.Microphone() as source:\n",
    "        print(\"Please speak the company name...\")\n",
    "        speak(\"Please speak the company name\")\n",
    "        recognizer.adjust_for_ambient_noise(source)\n",
    "        try:\n",
    "            audio = recognizer.listen(source, timeout=5)\n",
    "            text = recognizer.recognize_google(audio)\n",
    "            print(f\"You said: {text}\")\n",
    "            speak(f\"You said {text}\")\n",
    "            return text.upper()\n",
    "        except Exception as e:\n",
    "            print(f\"Error in voice recognition: {e}\")\n",
    "            speak(\"I couldn't understand that. Please try again\")\n",
    "            return None\n",
    "\n",
    "def extract_ticker(spoken_text):\n",
    "    \"\"\"Extract ticker symbol from spoken text using S&P 500 companies list\"\"\"\n",
    "    if not spoken_text:\n",
    "        return None\n",
    "\n",
    "    sp500_url = \"https://en.wikipedia.org/wiki/List_of_S%26P_500_companies\"\n",
    "    tables_sp500 = pd.read_html(sp500_url)\n",
    "    sp500_tickers = tables_sp500[0]['Symbol'].tolist()\n",
    "\n",
    "    # Get NASDAQ tickers\n",
    "    nasdaq_url = \"https://en.wikipedia.org/wiki/Nasdaq-100\"\n",
    "    tables_nasdaq = pd.read_html(nasdaq_url)\n",
    "    nasdaq_tickers = tables_nasdaq[4]['Symbol'].tolist()\n",
    "\n",
    "    # Combine both ticker lists\n",
    "    known_tickers = list(set(sp500_tickers + nasdaq_tickers))\n",
    "\n",
    "    words = spoken_text.split()\n",
    "    for word in words:\n",
    "        if word in known_tickers:\n",
    "            return word\n",
    "    return None\n",
    "\n",
    "def get_news(ticker):\n",
    "    \"\"\"Fetch news using Alpha Vantage API\"\"\"\n",
    "    api_key = 'ENIPDF3XPHW9IUUE'\n",
    "    url = f'https://www.alphavantage.co/query?function=NEWS_SENTIMENT&tickers={ticker}&limit=3&apikey={api_key}'\n",
    "\n",
    "    response = requests.get(url)\n",
    "    if response.status_code == 200:\n",
    "        return response.json()\n",
    "    return None\n",
    "\n",
    "def get_article_text(url):\n",
    "    \"\"\"Extract text from article URL\"\"\"\n",
    "    try:\n",
    "        response = requests.get(url)\n",
    "        soup = BeautifulSoup(response.text, 'html.parser')\n",
    "        paragraphs = soup.find_all(['h1', 'p'])\n",
    "        return ' '.join([p.get_text() for p in paragraphs])\n",
    "    except Exception as e:\n",
    "        print(f\"Error fetching article: {e}\")\n",
    "        return None\n",
    "\n",
    "def summarize_text(text):\n",
    "    \"\"\"Summarize text\"\"\"\n",
    "    if not text:\n",
    "        return \"Unable to summarize article.\"\n",
    "\n",
    "    # Example summarization logic (to be replaced with an actual summarizer)\n",
    "    return text[:200] + \"...\" if len(text) > 200 else text\n",
    "\n",
    "def format_news(news_data):\n",
    "    \"\"\"Format news data with summaries and read them aloud\"\"\"\n",
    "    if not news_data or 'feed' not in news_data:\n",
    "        msg = \"No news available.\"\n",
    "        speak(msg)\n",
    "        return msg\n",
    "\n",
    "    formatted_output = []\n",
    "    for i, article in enumerate(news_data['feed'][:3], 1):\n",
    "        article_text = get_article_text(article['url'])\n",
    "        if article_text:\n",
    "            summary = summarize_text(article_text)\n",
    "            article_content = (\n",
    "                f\"Article {i}:\\n\"\n",
    "                f\"Title: {article['title']}\\n\"\n",
    "                f\"Source: {article['source']}\\n\"\n",
    "                f\"Summary: {summary}\\n\"\n",
    "            )\n",
    "            formatted_output.append(article_content)\n",
    "\n",
    "            # Read each article\n",
    "            speak(f\"Article {i}\")\n",
    "            #time.sleep(0.5)\n",
    "            speak(f\"Title: {article['title']}\")\n",
    "            #time.sleep(0.5)\n",
    "            speak(f\"From: {article['source']}\")\n",
    "            #time.sleep(0.5)\n",
    "            speak(f\"Summary: {summary}\")\n",
    "            #time.sleep(1)  # Pause between articles\n",
    "\n",
    "    return '\\n'.join(formatted_output)\n",
    "\n",
    "def main():\n",
    "    print(\"Welcome to the Stock News Assistant!\")\n",
    "    speak(\"Welcome to the Stock News Assistant!\")\n",
    "    time.sleep(0.5)\n",
    "    speak(\"Say exit to quit.\")\n",
    "    time.sleep(1)\n",
    "\n",
    "    while True:\n",
    "        # Step 1: Get voice input\n",
    "        spoken_text = get_voice_input()\n",
    "        if not spoken_text:\n",
    "            continue\n",
    "\n",
    "        # Check for exit command\n",
    "        if 'EXIT' in spoken_text:\n",
    "            speak(\"Thank you for using the Stock News Assistant. Goodbye!\")\n",
    "            break\n",
    "\n",
    "        # Step 2: Extract ticker\n",
    "        ticker = extract_ticker(spoken_text)\n",
    "        if not ticker:\n",
    "            speak(\"Could not identify a ticker symbol. Please try again.\")\n",
    "            continue\n",
    "\n",
    "        msg = f\"Processing news for {ticker}...\"\n",
    "        print(msg)\n",
    "        speak(msg)\n",
    "\n",
    "        # Step 3: Fetch news\n",
    "        news_data = get_news(ticker)\n",
    "        if not news_data:\n",
    "            speak(\"Could not fetch news data. Please try again.\")\n",
    "            continue\n",
    "\n",
    "        # Step 4 & 5: Format and summarize news\n",
    "        formatted_news = format_news(news_data)\n",
    "        print(\"\\n\" + formatted_news)\n",
    "\n",
    "        speak(\"You can say another company name or say exit to quit.\")\n",
    "        time.sleep(1)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "481837c2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
